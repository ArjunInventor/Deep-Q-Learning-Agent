{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_worker.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMfkuL0iNQNcipdhRyUzaie"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNt38HdEoAGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Clone Repository\n",
        "repo = \"arjuninventor\" #@param [\"arjuninventor\", \"lawrathod\"]\n",
        "!git clone https://github.com/$repo/Deep-Q-Learning-Agent\n",
        "!mv Deep-Q-Learning-Agent/* .\n",
        "!rm -R Deep-Q-Learning-Agent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23YQzdw_nHAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "import datetime\n",
        "from collections import deque\n",
        "from envs.rover_lander_1 import rover_lander_1\n",
        "import tqdm\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-7jcWXPnmxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MASTER_ENDPOINT = \"localhost:5000\"\n",
        "WORKER_NAME = \"\"\n",
        "MAX_EPISODES = 5_000\n",
        "SHOW_PREVIEW = True\n",
        "AGGREGATE_STATS_EVERY = 10\n",
        "\n",
        "TRAIN_PARAMS = {}\n",
        "\n",
        "id = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrDq0XZ8npZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def connect():\n",
        "    id = int(requests.get(MASTER_ENDPOINT + f\"/master/connect?worker_name={WORKER_NAME}&max_episodes={MAX_EPISODES}&current_episode=0\"))\n",
        "    \n",
        "def update(properties=[]):\n",
        "    requests.get(MASTER_ENDPOINT + f\"/master/update?id={id}\" + \"&\".join(properties[0] + \"=\" + properties[1]))\n",
        "    \n",
        "def send_model(model_path):\n",
        "    files = {'model': open(model_path,'rb')}\n",
        "    r = requests.post(MASTER_ENDPOINT + f\"/master/send_model?id={id}\", files=files)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5_7Kho5nrNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class customCallback(tf.keras.callbacks.Callback): \n",
        "    def on_epoch_end(self, epoch, logs={}): \n",
        "        update((\"acc\", logs.get('acc')),\n",
        "                (\"loss\", logs.get('loss')),\n",
        "                (\"mse\", logs.get('mse')),\n",
        "                (\"epocs\", epoch))\n",
        "                \n",
        "    def on_train_end(self, logs=None):\n",
        "        update((\"last_trained\", \"curr_time\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDdRPvepns_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent:\n",
        "    def __init__(self):\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_decay = .996\n",
        "        self.memory = deque(maxlen=1000000)\n",
        "        self.model = self.build_model()\n",
        "    \n",
        "    def create_model(self):\n",
        "        pass\n",
        "    \n",
        "    def save_model(self, local_only=True):\n",
        "        self.model.save(f\"saved_model/{WORKER_NAME}.h5\")\n",
        "        if not local_only:\n",
        "            send_model(f\"saved_model/{WORKER_NAME}.h5\")\n",
        "    \n",
        "    def update_replay_memory(self):\n",
        "        pass\n",
        "    \n",
        "    def train(self):\n",
        "        pass\n",
        "    \n",
        "    def qs(self):\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4ThuaEf0sBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = rover_lander_1()\n",
        "agent = Agent()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9k3l9Wh0s0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for episode in tqdm(range(0, MAX_EPISODES), ascii=True, unit='episodes'):\n",
        "    # episode_reward = 0\n",
        "    # step = 1\n",
        "    # current_state = env.reset()\n",
        "    # done = False\n",
        "    # while not done:\n",
        "    #     if np.random.random() > agent.epsilon:\n",
        "    #         action = np.argmax(agent.get_qs(current_state))\n",
        "    #     else:\n",
        "    #         action = env.random_action_sample()\n",
        "            \n",
        "    # new_state, reward, done = env.step(action)\n",
        "    # episode_reward += reward\n",
        "    \n",
        "    # if SHOW_PREVIEW and not episode % AGGREGATE_STATS_EVERY:\n",
        "    #         env.render()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}